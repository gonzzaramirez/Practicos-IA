Trabajo Pr谩ctico 5: Inteligencia Artificial Conexionista (RNA)
Este proyecto implementa y valida modelos de Redes Neuronales Artificiales (RNA) para resolver un problema de clasificaci贸n utilizando datasets est谩ndar (Titanic o Iris).

 Requisitos T茅cnicos
Lenguaje y Entorno

Lenguaje: Python.

Entorno recomendado: Jupyter Notebook / Google Colab o Scripts de Python.

Frameworks y Librer铆as:

Scikit-learn: Para la implementaci贸n de modelos MLPClassifier, preprocesamiento y m茅tricas.

Pandas: Manipulaci贸n y an谩lisis de datos.

NumPy: C谩lculo num茅rico.

Matplotlib / Seaborn: Visualizaci贸n de datos y gr谩ficas de m茅tricas.

(Opcional) PyTorch o TensorFlow-Keras si se requieren modelos de Deep Learning m谩s complejos.

Dataset

Fuente: Repositorio UCI Machine Learning o Kaggle.

Selecci贸n: Dataset TITANIC o IRIS.

Tipo de problema: Clasificaci贸n.

锔 Requerimientos del C贸digo
El c贸digo debe estar estructurado siguiendo un pipeline de flujo de trabajo de Machine Learning, cubriendo las siguientes fases:

1. Fase de Preprocesamiento
   El c贸digo debe incluir funciones para limpiar y preparar los datos antes del entrenamiento:

Carga de datos: Importaci贸n del dataset seleccionado.

Limpieza: Detecci贸n y tratamiento de valores nulos/faltantes y outliers.

Transformaci贸n:

Codificaci贸n de variables categ贸ricas/nominales (One-Hot Encoding o asignaci贸n num茅rica).

Escalado y normalizaci贸n de datos (StandardScaler o MinMaxScaler) .

Balanceo de clases: Implementaci贸n de t茅cnicas de Over-Sampling o Under-Sampling si el dataset est谩 desequilibrado.

Divisi贸n de datos: Separaci贸n del conjunto en Training, Validation y Test (o uso de Cross-Validation con k-folds).

2. Fase de Procesamiento (Modelado)
   Se debe implementar la construcci贸n y entrenamiento de m铆nimo 3 modelos distintos de RNA.

Configuraci贸n de los Modelos (Hiperpar谩metros): El c贸digo debe permitir variar y experimentar con los siguientes par谩metros para cada modelo:

Arquitectura:

N煤mero de capas ocultas.

N煤mero de neuronas por capa.

Algoritmos de optimizaci贸n (Solvers): Comparar entre l-bfgs, sgd, y adam.

Funciones de activaci贸n: (ej. ReLU, Tanh, Logistic).

Par谩metros de entrenamiento:

Epochs: N煤mero de iteraciones durante el entrenamiento.

Learning Rate (Tasa de aprendizaje): Velocidad de modificaci贸n de pesos.

Intervalo de iteraciones: Control del estado del entrenamiento.

3. Fase de Posprocesamiento y Evaluaci贸n
   El c贸digo debe generar resultados cuantificables para comparar los modelos dise帽ados.

M茅tricas requeridas: Para cada modelo, se deben calcular e imprimir :

Matriz de Confusi贸n.

Accuracy (Exactitud).

Precision (Precisi贸n).

Recall (Sensibilidad).

F1-Score.

An谩lisis Comparativo:

El script debe permitir comparar m茅tricas de Entrenamiento vs. Validaci贸n para detectar Overfitting (Sobreajuste) o Underfitting (Subajuste).

Medici贸n del tiempo de ejecuci贸n de cada entrenamiento.

 Ejecuci贸n
El entregable debe ser capaz de ejecutar el flujo completo:

Ingesta y limpieza de datos.

Entrenamiento de los 3 modelos configurados.

Impresi贸n en consola o visualizaci贸n gr谩fica de la tabla comparativa de m茅tricas para determinar el mejor modelo.
